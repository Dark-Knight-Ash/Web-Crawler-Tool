 HEAD
# üï∏Ô∏è Web Crawler Tool

A powerful and user-friendly **Streamlit** app that crawls websites, extracts internal URLs, and identifies **URL parameters**. Visualize and filter results easily with built-in charts and download options.



## üöÄ Features

- üîó Crawl internal links up to a chosen depth
- üß† Extract and display URL parameters
- üìä Visualize parameter frequency with charts
- üì• Download results as JSON or CSV
- üßæ Crawl history stored in session
- ‚è±Ô∏è Timer to track crawl duration
- üóÇÔ∏è Sidebar navigation with interactive UI



## üñºÔ∏è Live Demo

> [Link to Streamlit Cloud App (Add after deployment)](https://web-crawler-tool.streamlit.app/)



## üì∏ Screenshots

![Screenshot](screenshot.png)



## üõ†Ô∏è Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/web-crawler-tool.git
cd web-crawler-tool

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # On Windows

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py

# Web-Crawler-Tool
A Streamlit-based tool to crawl URLs and extract parameters.
 ec803ac3fbe3df60cd4f1fd681bd7de9ce06b3ce
